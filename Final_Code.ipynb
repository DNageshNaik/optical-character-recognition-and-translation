{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Final_Code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DNageshNaik/optical-character-recognition-and-translation/blob/main/Final_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bShyBZwRcIS"
      },
      "source": [
        "### *************   Model 1  *************************"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "AKjAx8iPz3xu",
        "outputId": "7c25ceda-1b30-4b69-e33b-ffc6c92e40ea"
      },
      "source": [
        "#connecting to the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \"\"\"\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1e249d455b40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#connecting to the drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nF2I4e9N26Ba",
        "outputId": "bfd9cf3d-41b9-48f7-8e32-ef260e1e1b53"
      },
      "source": [
        "#importing libraries for layers and model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import backend as tf_keras_backend\n",
        "\n",
        "tf_keras_backend.set_image_data_format('channels_last')\n",
        "tf_keras_backend.image_data_format()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'channels_last'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHIjDtqP2u1-",
        "outputId": "3b072277-eb48-4dae-edcc-fe8ecb4aa6b5"
      },
      "source": [
        "#describing the model inputs and outputs\n",
        "input_data = layers.Input(name='the_input', shape=(128,64,1), dtype='float32')  # (None, 128, 64, 1)\n",
        "\n",
        "# Convolution layer (VGG)\n",
        "iam_layers = layers.Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)\n",
        "iam_layers = layers.BatchNormalization()(iam_layers)\n",
        "iam_layers = layers.Activation('relu')(iam_layers)\n",
        "iam_layers = layers.MaxPooling2D(pool_size=(2, 2), name='max1')(iam_layers)  # (None,64, 32, 64)\n",
        "\n",
        "iam_layers = layers.Conv2D(128, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(iam_layers)\n",
        "iam_layers = layers.BatchNormalization()(iam_layers)\n",
        "iam_layers = layers.Activation('relu')(iam_layers)\n",
        "iam_layers = layers.MaxPooling2D(pool_size=(2, 2), name='max2')(iam_layers)\n",
        "\n",
        "iam_layers = layers.Conv2D(256, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(iam_layers)\n",
        "iam_layers = layers.BatchNormalization()(iam_layers)\n",
        "iam_layers = layers.Activation('relu')(iam_layers)\n",
        "iam_layers = layers.Conv2D(256, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(iam_layers)\n",
        "iam_layers = layers.BatchNormalization()(iam_layers)\n",
        "iam_layers = layers.Activation('relu')(iam_layers)\n",
        "iam_layers = layers.MaxPooling2D(pool_size=(1, 2), name='max3')(iam_layers)  # (None, 32, 8, 256)\n",
        "\n",
        "iam_layers = layers.Conv2D(512, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(iam_layers)\n",
        "iam_layers = layers.BatchNormalization()(iam_layers)\n",
        "iam_layers = layers.Activation('relu')(iam_layers)\n",
        "iam_layers = layers.Conv2D(512, (3, 3), padding='same', name='conv6')(iam_layers)\n",
        "iam_layers = layers.BatchNormalization()(iam_layers)\n",
        "iam_layers = layers.Activation('relu')(iam_layers)\n",
        "iam_layers = layers.MaxPooling2D(pool_size=(1, 2), name='max4')(iam_layers)\n",
        "\n",
        "iam_layers = layers.Conv2D(512, (2, 2), padding='same', kernel_initializer='he_normal', name='con7')(iam_layers)\n",
        "iam_layers = layers.BatchNormalization()(iam_layers)\n",
        "iam_layers = layers.Activation('relu')(iam_layers)\n",
        "\n",
        "# CNN to RNN\n",
        "iam_layers = layers.Reshape(target_shape=((32, 2048)), name='reshape')(iam_layers)\n",
        "iam_layers = layers.Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(iam_layers)\n",
        "\n",
        "# RNN layer\n",
        "# layer ten\n",
        "iam_layers = layers.Bidirectional(layers.LSTM(units=256, return_sequences=True))(iam_layers)\n",
        "# layer nine\n",
        "iam_layers = layers.Bidirectional(layers.LSTM(units=256, return_sequences=True))(iam_layers)\n",
        "iam_layers = layers.BatchNormalization()(iam_layers)\n",
        "\n",
        "# transforms RNN output to character activations:\n",
        "iam_layers = layers.Dense(80, kernel_initializer='he_normal', name='dense2')(iam_layers)\n",
        "iam_outputs = layers.Activation('softmax', name='softmax')(iam_layers)\n",
        "\n",
        "labels = layers.Input(name='the_labels', shape=[16], dtype='float32')\n",
        "input_length = layers.Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = layers.Input(name='label_length', shape=[1], dtype='int64')\n",
        "\n",
        "iam_model_pred = None\n",
        "iam_model_pred = Model(inputs=input_data, outputs=iam_outputs)\n",
        "iam_model_pred.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "the_input (InputLayer)       [(None, 128, 64, 1)]      0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 128, 64, 64)       640       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 128, 64, 64)       256       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 128, 64, 64)       0         \n",
            "_________________________________________________________________\n",
            "max1 (MaxPooling2D)          (None, 64, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 64, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 64, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 64, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "max2 (MaxPooling2D)          (None, 32, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 32, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 32, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 32, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 32, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 32, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "max3 (MaxPooling2D)          (None, 32, 8, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv5 (Conv2D)               (None, 32, 8, 512)        1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 32, 8, 512)        2048      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 32, 8, 512)        0         \n",
            "_________________________________________________________________\n",
            "conv6 (Conv2D)               (None, 32, 8, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 32, 8, 512)        2048      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 32, 8, 512)        0         \n",
            "_________________________________________________________________\n",
            "max4 (MaxPooling2D)          (None, 32, 4, 512)        0         \n",
            "_________________________________________________________________\n",
            "con7 (Conv2D)                (None, 32, 4, 512)        1049088   \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 32, 4, 512)        2048      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 32, 4, 512)        0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 32, 2048)          0         \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 32, 64)            131136    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 32, 512)           657408    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 32, 512)           1574912   \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 32, 512)           2048      \n",
            "_________________________________________________________________\n",
            "dense2 (Dense)               (None, 32, 80)            41040     \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 32, 80)            0         \n",
            "=================================================================\n",
            "Total params: 7,964,304\n",
            "Trainable params: 7,958,800\n",
            "Non-trainable params: 5,504\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXYdbGAg6T13"
      },
      "source": [
        "#function to return file path and label\n",
        "def get_paths_and_gts(partition_split_file):\n",
        "    \"\"\"\n",
        "    read a string like(which can be found in each line of words.txt file):\n",
        "    'a01-000u-00-00 ok 154 408 768 27 51 AT A'\n",
        "    and extract 'a01-000u-00-00': location of the image with sub-folders, to read it from the directories\n",
        "                'ok'            : processing status. ok means good, presumably.\n",
        "                'A'             : ground truth text\n",
        "\n",
        "    Then, pre-process using function defined above\n",
        "    \"\"\"\n",
        "    \n",
        "    data_location = '/content/drive/My Drive/AI in Manufac/project/data/words_zips'\n",
        "\n",
        "    # a list to store paths to images and ground truth texts\n",
        "    paths_and_gts = []\n",
        "    \n",
        "    # open the file\n",
        "    with open(partition_split_file) as f:\n",
        "        # go through each line\n",
        "        for line in f:\n",
        "            # if a line is empty or commented with #, ignore that line\n",
        "            if not line or line.startswith('#'):\n",
        "                continue\n",
        "            \n",
        "            # in the text file, each line is seperated with '\\n', so `strip` first\n",
        "            # then string like 'a01-000u-00-00 ok 154 408 768 27 51 AT A' has to split to a list by spaces\n",
        "            line_split = line.strip().split(' ')\n",
        "            \n",
        "            # the first item of the list contains path information, so split that by '-'\n",
        "            directory_split = line_split[0].split('-')\n",
        "            \n",
        "            # now use all the above and concatenate to a string to make a path to an image\n",
        "            image_location = f'{data_location}/{directory_split[0]}/{directory_split[0]}-{directory_split[1]}/{line_split[0]}.png'\n",
        "            \n",
        "            # in a string like 'a01-000u-00-00 ok 154 408 768 27 51 AT A', text from 9th split is the ground truth text.\n",
        "            gt_text = ' '.join(line_split[8:])\n",
        "            \n",
        "            # ignore a sample(image and ground truth text), if the ground truth has more than 16 letters\n",
        "            # if len(gt_text) > 16:\n",
        "                # continue\n",
        "            \n",
        "            # now, append the image location and ground truth text of that image as a list to \n",
        "            paths_and_gts.append([image_location, gt_text])\n",
        "    \n",
        "    return paths_and_gts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1p7Cp3u0he1",
        "outputId": "f951cd7e-3d27-4506-99fe-94fe6d802d61"
      },
      "source": [
        "# the above function output will look like this\n",
        "test_files = get_paths_and_gts('/content/drive/My Drive/AI in Manufac/project/data/test_files.txt')\n",
        "test_files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['/content/drive/My Drive/AI in Manufac/project/data/words_zips/a01/a01-000u/a01-000u-00-04.png',\n",
              "  'Mr.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlOC_azjFlNc",
        "outputId": "414b409a-6cb7-42d7-bc0f-e7f8be3d5a41"
      },
      "source": [
        "test_files = [['/content/drive/My Drive/AI in Manufac/project/Group2.jpeg',\n",
        "  'EDUCATION']]\n",
        "test_files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['/content/drive/My Drive/AI in Manufac/project/Group2.jpeg', 'EDUCATION']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKE4EiYK69nn"
      },
      "source": [
        "#pre processing\n",
        "#function to perform padding\n",
        "def add_padding(img, old_w, old_h, new_w, new_h):\n",
        "    h1, h2 = int((new_h - old_h) / 2), int((new_h - old_h) / 2) + old_h\n",
        "    w1, w2 = int((new_w - old_w) / 2), int((new_w - old_w) / 2) + old_w\n",
        "    img_pad = np.ones([new_h, new_w, 3]) * 255\n",
        "    img_pad[h1:h2, w1:w2, :] = img\n",
        "    return img_pad\n",
        "\n",
        "#function to convert the image to size of (64, 128, 3)\n",
        "def fix_size(img, target_w, target_h):\n",
        "    \n",
        "    h, w = img.shape[:2]\n",
        "    if w < target_w and h < target_h:\n",
        "        img = add_padding(img, w, h, target_w, target_h)\n",
        "    elif w >= target_w and h < target_h:\n",
        "        new_w = target_w\n",
        "        new_h = int(h * new_w / w)\n",
        "        new_img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "        img = add_padding(new_img, new_w, new_h, target_w, target_h)\n",
        "    elif w < target_w and h >= target_h:\n",
        "        new_h = target_h\n",
        "        new_w = int(w * new_h / h)\n",
        "        new_img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "        img = add_padding(new_img, new_w, new_h, target_w, target_h)\n",
        "    else:\n",
        "        \"\"\"w>=target_w and h>=target_h \"\"\"\n",
        "        ratio = max(w / target_w, h / target_h)\n",
        "        new_w = max(min(target_w, int(w / ratio)), 1)\n",
        "        new_h = max(min(target_h, int(h / ratio)), 1)\n",
        "        new_img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "        img = add_padding(new_img, new_w, new_h, target_w, target_h)\n",
        "    return img\n",
        "\n",
        "#performs shaping, normalization and coloring\n",
        "def preprocess(path, img_w, img_h):\n",
        "    \"\"\" Pre-processing image for predicting \"\"\"\n",
        "    #print(path)\n",
        "    img = cv2.imread(path)\n",
        "    #print(img.shape)\n",
        "    #resizing the image to particular size (64, 128, 3)\n",
        "    img = fix_size(img, img_w, img_h)\n",
        "    #print(img.shape)\n",
        "    \n",
        "    #assigining values less than zero to zer0 and greater than zero to 1\n",
        "    img = np.clip(img, 0, 255)\n",
        "\n",
        "    #changing the interger to more useful and complex integer\n",
        "    img = np.uint8(img)\n",
        "\n",
        "    #convert an image to one color space to another\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    #chaging the values datatype to float\n",
        "    img = img.astype(np.float32)\n",
        "\n",
        "    #normalization\n",
        "    img /= 255\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ytotnk-IE3YL"
      },
      "source": [
        "test_files = [['/content/drive/My Drive/AI in Manufac/project/Group 2.png', 'ME6324']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xH_8oHsakXIl",
        "outputId": "ac6061f8-349f-4b8a-c8a4-86774c75ad90"
      },
      "source": [
        "# the above function output will look like this\n",
        "test_files = get_paths_and_gts('/content/drive/My Drive/AI in Manufac/project/data/test_files.txt')\n",
        "test_files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['/content/drive/My Drive/AI in Manufac/project/data/words_zips/a01/a01-000u/a01-000u-00-04.png',\n",
              "  'Mr.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "roMjNjj3lHpS"
      },
      "source": [
        "test_files = [['/content/drive/My Drive/AI in Manufac/project/images/WhatsApp Image 2020-12-10 at 13.14.24 (1).jpeg','']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "id": "JD-jtuy1lxXd",
        "outputId": "51d2f152-8f99-4f3a-ed58-bfdaae85355a"
      },
      "source": [
        "#plot the transformed image\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "sns.reset_orig()\n",
        "i = 1\n",
        "for i in range(1):\n",
        "    #print(test_files[i][1])\n",
        "    img = cv2.imread(test_files[i][0])\n",
        "    temp_processed_image = preprocess(path = test_files[i][0], img_w=128, img_h=64)\n",
        "    fig = plt.figure()\n",
        "    ax1 = fig.add_subplot(2,2,1)\n",
        "    ax1.imshow(img)\n",
        "    ax2 = fig.add_subplot(2,2,2)\n",
        "    ax2.imshow(temp_processed_image.T)\n",
        "    i = i+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-149-ed142892fc8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#print(test_files[i][1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtemp_processed_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_h\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0max1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-b80b7425dc4a>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(path, img_w, img_h)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m#print(img.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m#resizing the image to particular size (64, 128, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;31m#print(img.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-b80b7425dc4a>\u001b[0m in \u001b[0;36mfix_size\u001b[0;34m(img, target_w, target_h)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfix_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_w\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_h\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8UeIQNq3R6X"
      },
      "source": [
        "#will be doing the same thing for the test files and appending both preproccessed image and label to 2 strings\n",
        "import cv2\n",
        "import numpy as np\n",
        "test_images_processed = []\n",
        "original_test_texts = []\n",
        "for _, (test_image_path, original_test_text) in enumerate(test_files):\n",
        "        temp_processed_image = preprocess(path=test_image_path, img_w=128, img_h=64)\n",
        "        test_images_processed.append(temp_processed_image.T) \n",
        "        original_test_texts.append(original_test_text)\n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2otmeeLRqh37",
        "outputId": "ec082444-e5e3-4658-cc51-ab7c2e0bb0d7"
      },
      "source": [
        "#reshaping the test data\n",
        "test_images_processed = np.array(test_images_processed)\n",
        "test_images_processed = test_images_processed.reshape(1, 128, 64, 1)\n",
        "test_images_processed.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 128, 64, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HK3KY677q2VW",
        "outputId": "9784f865-f62c-4006-f73e-4dba9ad62ea4"
      },
      "source": [
        "#importing the trained model\n",
        "iam_model_pred.load_weights(filepath='/content/drive/My Drive/AI in Manufac/project/lstm-model-after-3rd-session.h5')\n",
        "test_predictions_encoded = iam_model_pred.predict(x=test_images_processed)\n",
        "\n",
        "# use CTC decoder to decode to text\n",
        "test_predictions_decoded = tf_keras_backend.get_value(tf_keras_backend.ctc_decode(test_predictions_encoded,\n",
        "                                                                                  input_length = np.ones(test_predictions_encoded.shape[0])*test_predictions_encoded.shape[1],\n",
        "                                                                                  greedy=True)[0][0])\n",
        "test_predictions_decoded.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FescdKeHrQFR",
        "outputId": "2861a754-9d46-4aeb-9167-5354985125e5"
      },
      "source": [
        "def numbered_array_to_text(numbered_array):\n",
        "    numbered_array = numbered_array[numbered_array != -1]\n",
        "    return \"\".join(letters[i] for i in numbered_array)\n",
        "\n",
        "letters = [' ', '!', '\"', '#', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "           '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?',\n",
        "           'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
        "           'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
        "           'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
        "           'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
        "\n",
        "num_classes = len(letters) + 1\n",
        "\n",
        "#predicting the 5 test data labels\n",
        "for i in range(1):\n",
        "  #print(\"original_text = \", original_test_texts[i])\n",
        "  print(\"predicted text = \", numbered_array_to_text(test_predictions_decoded[i]))\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted text =  7MEB3Z4\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALK5bFqckATV",
        "outputId": "25a209df-9697-45c6-eb83-09d5516aa48f"
      },
      "source": [
        "#autocorrecting the pedictions\n",
        "test_sentences = []\n",
        "for i in range(1):\n",
        "    string = numbered_array_to_text(test_predictions_decoded[i])\n",
        "    #remove characters\n",
        "    k = ''.join(e for e in string if e.isalnum())\n",
        "    #remove numbers\n",
        "    k = ''.join([i for i in k if not i.isdigit()])\n",
        "    test_sentences.append(k)\n",
        "\n",
        "test_sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['MEBZ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfdNaCb1VskV"
      },
      "source": [
        "#### **************** Model 2 ********************"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5-iSlVpV3NK"
      },
      "source": [
        "#importing the libraries\n",
        "import os, sys\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU, Dense, Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5bi1dEQXNVh"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20\n",
        "LSTM_NODES =256\n",
        "NUM_SENTENCES = 20000\n",
        "MAX_SENTENCE_LENGTH = 50\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_SIZE = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j66uui23XQfn"
      },
      "source": [
        "#Redifining input and output sequences\n",
        "input_sentences = []\n",
        "output_sentences = []\n",
        "output_sentences_inputs = []\n",
        "\n",
        "count = 0\n",
        "for line in open(r'/content/drive/My Drive/AI in Manufac/project/Translation/data/fra.txt', encoding=\"utf-8\"):\n",
        "    count += 1\n",
        "    #print(line.rstrip().split('\\t')[0])\n",
        "\n",
        "    if count > NUM_SENTENCES:\n",
        "        break\n",
        "\n",
        "    if '\\t' not in line:\n",
        "        continue\n",
        "    sss = line.rstrip().split('\\t')\n",
        "    input_sentence = sss[0]\n",
        "    output = sss[1]\n",
        "    #print(input_sentence, output)\n",
        "    #sss = line.rstrip().split('\\t')\n",
        "    '''\n",
        "    for at, bt in enumerate(sss):\n",
        "      if at==0:\n",
        "        input_sentence = bt\n",
        "      elif at==1:\n",
        "        output = bt\n",
        "        break\n",
        "    '''\n",
        "    output_sentence = output + ' <eos>'\n",
        "    output_sentence_input = '<sos> ' + output\n",
        "\n",
        "    input_sentences.append(input_sentence)\n",
        "    output_sentences.append(output_sentence)\n",
        "    output_sentences_inputs.append(output_sentence_input)\n",
        "\n",
        "#print(\"num samples input:\", len(input_sentences))\n",
        "#print(\"num samples output:\", len(output_sentences))\n",
        "#print(\"num samples output input:\", len(output_sentences_inputs))\n",
        "#for i in range(4):\n",
        "#  print(\"see:\", input_sentences[i], output_sentences[i], output_sentences_inputs[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzx7eHQ6LCXk",
        "outputId": "fdc32a66-42a7-477e-d424-c6e265afb543"
      },
      "source": [
        "#demo\n",
        "print(input_sentences[172])\n",
        "print(output_sentences[172])\n",
        "print(output_sentences_inputs[172])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I'm Tom.\n",
            "Je suis Tom. <eos>\n",
            "<sos> Je suis Tom.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzeepw_mK8JQ",
        "outputId": "da86c144-334e-49e0-8f05-673214156440"
      },
      "source": [
        "#Tokenization splitting sentences into words\n",
        "input_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "input_tokenizer.fit_on_texts(input_sentences)\n",
        "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
        "\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "print('Total unique words in the input: %s' % len(word2idx_inputs))\n",
        "\n",
        "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
        "print(\"Length of longest sentence in input: %g\" % max_input_len)\n",
        "\n",
        "output_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
        "output_tokenizer.fit_on_texts(output_sentences + output_sentences_inputs)\n",
        "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
        "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "print('Total unique words in the output: %s' % len(word2idx_outputs))\n",
        "\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
        "print(\"Length of longest sentence in the output: %g\" % max_out_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total unique words in the input: 3518\n",
            "Length of longest sentence in input: 6\n",
            "Total unique words in the output: 9546\n",
            "Length of longest sentence in the output: 12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXOtbE8AMcAN",
        "outputId": "0634e0ee-6033-4e13-9cbb-bf7f3e7c7359"
      },
      "source": [
        "print(word2idx_inputs[\"i'm\"])\n",
        "print(word2idx_inputs[\"ill\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAsAipeGMqP1",
        "outputId": "42d7690a-7605-4afd-a230-942fd6435b36"
      },
      "source": [
        "print(word2idx_outputs[\"<sos>\"])\n",
        "print(word2idx_outputs[\"je\"])\n",
        "print(word2idx_outputs[\"suis\"])\n",
        "print(word2idx_outputs[\"malade.\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "3\n",
            "6\n",
            "184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY1_FzafYuHg",
        "outputId": "699b0dfc-9b2b-4d44-fb85-a1cc90ba45c4"
      },
      "source": [
        "#encoding and decoding \n",
        "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
        "print(\"encoder_input_sequences.shape:\", encoder_input_sequences.shape)\n",
        "print(\"encoder_input_sequences[172]:\", encoder_input_sequences[172])\n",
        "\n",
        "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
        "print(\"decoder_input_sequences.shape:\", decoder_input_sequences.shape)\n",
        "print(\"decoder_input_sequences[172]:\", decoder_input_sequences[172])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder_input_sequences.shape: (20000, 6)\n",
            "encoder_input_sequences[172]: [0 0 0 0 6 7]\n",
            "decoder_input_sequences.shape: (20000, 12)\n",
            "decoder_input_sequences[172]: [ 2  3  6 52  0  0  0  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPgHxgFnY2fU"
      },
      "source": [
        "#word embeddings\n",
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "\n",
        "glove_file = open(r'/content/drive/My Drive/AI in Manufac/project/Translation/data/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary[word] = vector_dimensions\n",
        "glove_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFob7LSkZHBA"
      },
      "source": [
        "#creating a embedding matrix \n",
        "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
        "embedding_matrix = zeros((num_words, EMBEDDING_SIZE))\n",
        "for word, index in word2idx_inputs.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mS_jJRMnRAQr",
        "outputId": "0b7ea297-4f2f-4dc5-c8f9-6136a0baa33d"
      },
      "source": [
        "print(embeddings_dictionary[\"ill\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.12648    0.1366     0.22192   -0.025204  -0.7197     0.66147\n",
            "  0.48509    0.057223   0.13829   -0.26375   -0.23647    0.74349\n",
            "  0.46737   -0.462      0.20031   -0.26302    0.093948  -0.61756\n",
            " -0.28213    0.1353     0.28213    0.21813    0.16418    0.22547\n",
            " -0.98945    0.29624   -0.62476   -0.29535    0.21534    0.92274\n",
            "  0.38388    0.55744   -0.14628   -0.15674   -0.51941    0.25629\n",
            " -0.0079678  0.12998   -0.029192   0.20868   -0.55127    0.075353\n",
            "  0.44746   -0.71046    0.75562    0.010378   0.095229   0.16673\n",
            "  0.22073   -0.46562   -0.10199   -0.80386    0.45162    0.45183\n",
            "  0.19869   -1.6571     0.7584    -0.40298    0.82426   -0.386\n",
            "  0.0039546  0.61318    0.02701   -0.3308    -0.095652  -0.082164\n",
            "  0.7858     0.13394   -0.32715   -0.31371   -0.20247   -0.73001\n",
            " -0.49343    0.56445    0.61038    0.36777   -0.070182   0.44859\n",
            " -0.61774   -0.18849    0.65592    0.44797   -0.10469    0.62512\n",
            " -1.9474    -0.60622    0.073874   0.50013   -1.1278    -0.42066\n",
            " -0.37322   -0.50538    0.59171    0.46534   -0.42482    0.83265\n",
            "  0.081548  -0.44147   -0.084311  -1.2304   ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zi-jkwtGRE-x",
        "outputId": "e03fc4f3-8557-4d17-f4da-7af8b3d99bd8"
      },
      "source": [
        "print(embedding_matrix[539])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.12648     0.1366      0.22192    -0.025204   -0.71969998  0.66147\n",
            "  0.48508999  0.057223    0.13829    -0.26374999 -0.23647     0.74348998\n",
            "  0.46737    -0.46200001  0.20031001 -0.26302001  0.093948   -0.61756003\n",
            " -0.28213     0.1353      0.28213     0.21813001  0.16418     0.22547001\n",
            " -0.98944998  0.29624    -0.62475997 -0.29534999  0.21534     0.92273998\n",
            "  0.38387999  0.55743998 -0.14628001 -0.15673999 -0.51941001  0.25628999\n",
            " -0.0079678   0.12998    -0.029192    0.20868    -0.55127001  0.075353\n",
            "  0.44746    -0.71046001  0.75562     0.010378    0.095229    0.16673\n",
            "  0.22073001 -0.46562001 -0.10199    -0.80386001  0.45162001  0.45183\n",
            "  0.19869    -1.65709996  0.75840002 -0.40298     0.82426    -0.38600001\n",
            "  0.0039546   0.61317998  0.02701    -0.3308     -0.095652   -0.082164\n",
            "  0.78579998  0.13394    -0.32714999 -0.31371    -0.20247    -0.73000997\n",
            " -0.49342999  0.56445003  0.61037999  0.36776999 -0.070182    0.44859001\n",
            " -0.61773998 -0.18849     0.65592003  0.44797    -0.10469     0.62511998\n",
            " -1.94739997 -0.60622001  0.073874    0.50013    -1.12779999 -0.42065999\n",
            " -0.37322    -0.50537997  0.59170997  0.46533999 -0.42482001  0.83265001\n",
            "  0.081548   -0.44147    -0.084311   -1.23039997]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtOWSZC0ZKr4"
      },
      "source": [
        "embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=max_input_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOlMLbkwZNtK",
        "outputId": "03b4d949-37d4-4575-84b1-d3c6fa214966"
      },
      "source": [
        "# Creating Model\n",
        "#performed on hot encoding and intialized encoder and decoder\n",
        "decoder_targets_one_hot = np.zeros((\n",
        "        len(input_sentences),\n",
        "        max_out_len,\n",
        "        num_words_output\n",
        "    ),\n",
        "    dtype='float32'\n",
        ")\n",
        "print(decoder_targets_one_hot.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 12, 9547)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf-G-umwZXKm"
      },
      "source": [
        "#creating the output decoder for the output\n",
        "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
        "for i, d in enumerate(decoder_output_sequences):\n",
        "#for i, d in enumerate(decoder_input_sequences):\n",
        "    for t, word in enumerate(d):\n",
        "        decoder_targets_one_hot[i, t, word] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjQlFcdyZZ7h"
      },
      "source": [
        "#creating an encoder for input\n",
        "encoder_inputs_placeholder = Input(shape=(max_input_len,))\n",
        "x = embedding_layer(encoder_inputs_placeholder)\n",
        "encoder = LSTM(LSTM_NODES, return_state=True)\n",
        "\n",
        "encoder_outputs, h, c = encoder(x)\n",
        "encoder_states = [h, c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5yODhs2ZeNZ"
      },
      "source": [
        "#creating an input decoder\n",
        "decoder_inputs_placeholder = Input(shape=(max_out_len,))\n",
        "\n",
        "decoder_embedding = Embedding(num_words_output, LSTM_NODES)\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
        "\n",
        "decoder_lstm = LSTM(LSTM_NODES, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSI3OIFPZifX"
      },
      "source": [
        "#dense layer with soft max activation function \n",
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbICO7bqZlLn"
      },
      "source": [
        "#compiling the model\n",
        "model = Model([encoder_inputs_placeholder,\n",
        "  decoder_inputs_placeholder], decoder_outputs)\n",
        "model.compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrG5LZHvZo3M",
        "outputId": "fd739558-14e8-40f5-b3d7-ed5d213a7cde"
      },
      "source": [
        "#training the model\n",
        "r = model.fit(\n",
        "    [encoder_input_sequences, decoder_input_sequences],\n",
        "    decoder_targets_one_hot,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_split=0.1,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "282/282 [==============================] - 17s 62ms/step - loss: 2.1584 - accuracy: 0.6989 - val_loss: 2.2110 - val_accuracy: 0.6842\n",
            "Epoch 2/20\n",
            "282/282 [==============================] - 17s 59ms/step - loss: 1.5840 - accuracy: 0.7629 - val_loss: 1.9784 - val_accuracy: 0.7153\n",
            "Epoch 3/20\n",
            "282/282 [==============================] - 17s 59ms/step - loss: 1.3698 - accuracy: 0.7943 - val_loss: 1.8731 - val_accuracy: 0.7330\n",
            "Epoch 4/20\n",
            "282/282 [==============================] - 16s 58ms/step - loss: 1.2401 - accuracy: 0.8102 - val_loss: 1.7802 - val_accuracy: 0.7419\n",
            "Epoch 5/20\n",
            "282/282 [==============================] - 17s 59ms/step - loss: 1.1412 - accuracy: 0.8223 - val_loss: 1.7227 - val_accuracy: 0.7500\n",
            "Epoch 6/20\n",
            "282/282 [==============================] - 16s 59ms/step - loss: 1.0645 - accuracy: 0.8316 - val_loss: 1.6876 - val_accuracy: 0.7566\n",
            "Epoch 7/20\n",
            "282/282 [==============================] - 17s 59ms/step - loss: 1.0007 - accuracy: 0.8400 - val_loss: 1.6764 - val_accuracy: 0.7559\n",
            "Epoch 8/20\n",
            "282/282 [==============================] - 17s 59ms/step - loss: 0.9519 - accuracy: 0.8474 - val_loss: 1.6557 - val_accuracy: 0.7599\n",
            "Epoch 9/20\n",
            "282/282 [==============================] - 17s 59ms/step - loss: 0.9063 - accuracy: 0.8541 - val_loss: 1.6404 - val_accuracy: 0.7600\n",
            "Epoch 10/20\n",
            "282/282 [==============================] - 16s 58ms/step - loss: 0.8664 - accuracy: 0.8603 - val_loss: 1.6539 - val_accuracy: 0.7623\n",
            "Epoch 11/20\n",
            "282/282 [==============================] - 17s 59ms/step - loss: 0.8277 - accuracy: 0.8658 - val_loss: 1.6441 - val_accuracy: 0.7646\n",
            "Epoch 12/20\n",
            "282/282 [==============================] - 17s 59ms/step - loss: 0.7964 - accuracy: 0.8711 - val_loss: 1.6769 - val_accuracy: 0.7648\n",
            "Epoch 13/20\n",
            "282/282 [==============================] - 16s 58ms/step - loss: 0.7666 - accuracy: 0.8758 - val_loss: 1.6576 - val_accuracy: 0.7665\n",
            "Epoch 14/20\n",
            "282/282 [==============================] - 16s 59ms/step - loss: 0.7381 - accuracy: 0.8808 - val_loss: 1.6606 - val_accuracy: 0.7683\n",
            "Epoch 15/20\n",
            "282/282 [==============================] - 16s 58ms/step - loss: 0.7147 - accuracy: 0.8845 - val_loss: 1.6829 - val_accuracy: 0.7660\n",
            "Epoch 16/20\n",
            "282/282 [==============================] - 17s 59ms/step - loss: 0.6948 - accuracy: 0.8884 - val_loss: 1.6838 - val_accuracy: 0.7684\n",
            "Epoch 17/20\n",
            "282/282 [==============================] - 17s 59ms/step - loss: 0.6757 - accuracy: 0.8912 - val_loss: 1.6865 - val_accuracy: 0.7693\n",
            "Epoch 18/20\n",
            "282/282 [==============================] - 17s 59ms/step - loss: 0.6565 - accuracy: 0.8940 - val_loss: 1.6880 - val_accuracy: 0.7700\n",
            "Epoch 19/20\n",
            "282/282 [==============================] - 16s 58ms/step - loss: 0.6424 - accuracy: 0.8971 - val_loss: 1.7132 - val_accuracy: 0.7688\n",
            "Epoch 20/20\n",
            "282/282 [==============================] - 17s 59ms/step - loss: 0.6329 - accuracy: 0.8994 - val_loss: 1.7488 - val_accuracy: 0.7659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X-_ypo6ZuxE"
      },
      "source": [
        "#Modifying the Model\n",
        "encoder_model = Model(encoder_inputs_placeholder, encoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5_bhYdBZxgk"
      },
      "source": [
        "decoder_state_input_h = Input(shape=(LSTM_NODES,))\n",
        "decoder_state_input_c = Input(shape=(LSTM_NODES,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp5v7cikZ0c7"
      },
      "source": [
        "decoder_inputs_single = Input(shape=(1,))\n",
        "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWD7jwpLZ3bB"
      },
      "source": [
        "decoder_outputs, h, c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MymQG6RaZ4jO"
      },
      "source": [
        "decoder_states = [h, c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF2gY0E3Z7__"
      },
      "source": [
        "decoder_model = Model(\n",
        "    [decoder_inputs_single] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wqjg-YghOqBO"
      },
      "source": [
        "### making predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04C5TlReZ-ED"
      },
      "source": [
        "#Making Predictions\n",
        "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
        "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaY5Yy6sb09p"
      },
      "source": [
        "def translate_sentence(input_seq):\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
        "    eos = word2idx_outputs['<eos>']\n",
        "    output_sentence = []\n",
        "\n",
        "    for _ in range(max_out_len):\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "        idx = np.argmax(output_tokens[0, 0, :])\n",
        "\n",
        "        if eos == idx:\n",
        "            break\n",
        "\n",
        "        word = ''\n",
        "\n",
        "        if idx > 0:\n",
        "            word = idx2word_target[idx]\n",
        "            output_sentence.append(word)\n",
        "\n",
        "        target_seq[0, 0] = idx\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return ' '.join(output_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xnV54PEVh3D",
        "outputId": "42a45415-389b-4882-be81-481fb3f631b2"
      },
      "source": [
        "test_sentences = ['EDUCATION']\n",
        "test_sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['EDUCATION']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-emALGmOStx",
        "outputId": "b2a03998-ed18-479d-fddf-0f949078cd83"
      },
      "source": [
        "#tokenising the test data\n",
        "test_tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "test_tokenizer.fit_on_texts(test_sentences)\n",
        "test_integer_seq = test_tokenizer.texts_to_sequences(test_sentences)\n",
        "\n",
        "max_test_len = max(len(sen) for sen in test_integer_seq)\n",
        "\n",
        "encoder_test_sequences = pad_sequences(test_integer_seq, maxlen=max_test_len)\n",
        "encoder_test_sequences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSZG3z9_CDyI",
        "outputId": "45797978-731d-49bb-81fb-7e1ded1f1f4d"
      },
      "source": [
        "for i in range(1):\n",
        "  #i = np.random.choice(len(test_sentences))\n",
        "  #print(i)\n",
        "  input_seq = encoder_test_sequences[i:i+1]\n",
        "  print(input_seq)\n",
        "  translation = translate_sentence(input_seq)\n",
        "  print('Input:', test_sentences[i])\n",
        "  print('Response:', translation)\n",
        "  print('--------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1]]\n",
            "Input: EDUCATION\n",
            "Response: je m'en suis !\n",
            "--------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}